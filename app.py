# import need packages
import os
import requests
import configparser
from bs4 import BeautifulSoup
import urllib3

import re
import time
import random
import datetime
from imgurpython import ImgurClient

# linebot-sdk packages
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *


app = Flask(__name__)

# API Config.ini
config = configparser.ConfigParser()
config.read("config.ini")

# Line Messenger API
line_bot_api = LineBotApi(config['line_bot']['Channel_Access_Token'])
handler = WebhookHandler(config['line_bot']['Channel_Secret'])
# Imgur image API
client_id = config['imgur_api']['Client_ID']
client_secret = config['imgur_api']['Client_Secret']
access_token = config['imgur_api']['Access_token']
refresh_token = config['imgur_api']['Refresh_token']
album_id = config['imgur_api']['Album_ID']

# requests.get å½è£å™¨
headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}

@app.route("/callback", methods=["POST"])
def callback():
    # get X-Line-Signature header value
    signature = request.headers['X-Line-Signature']

    # get request body as text
    body = request.get_data(as_text=True)
    # print("body:",body)
    app.logger.info("Request body: " + body)

    # handle webhook body
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'ok'

# è™•ç† title æ–‡å­—
def del_re(string):
    import re
    if re.search(r'^Re.\s*',string) != None:
        count = re.search(r'^Re.\s*',string).span()[1]
        return string[count:]
    else:
        return string

# ä»Šæ—¥æ™‚é–“
def today_date():
    today = datetime.date.today()
    today_format = today.strftime(("%m/%d"))
    if today_format.startswith("0"):
        return today_format[1:]
    else:
        return today_format

# æ˜¨æ—¥æ™‚é–“
def yesterday_date():
    yesterday = datetime.date.today() + datetime.timedelta(-1)
    yesterday_format = yesterday.strftime("%m/%d")
    if yesterday_format.startswith("0"):
        return yesterday_format[1:]
    else:
        return yesterday_format

# æŠ“å–ä¸Šä¸€é çš„ url
def ptt_upper_url(ptt_board_url,pages=5):
    url_list = [ptt_board_url]
    res = requests.get(ptt_board_url)
    soup = BeautifulSoup(res.text,"html.parser")

    pre_href = soup.select('div.btn-group a')[3]['href']
    board = pre_href.split('/')[2]
    pre_index = re.search('\d+',pre_href).group()
    index = int(pre_index)
    domain = 'https://www.ptt.cc/bbs/'
    for page in range(pages-1):
        index_url = domain + board + "/index" + str(index) + ".html"
        index -= 1
        url_list.append(index_url)

    return url_list

# ptt_over_18 href
def ptt_over18_href(href, pages=5):
    href_list = [href]
    urllib3.disable_warnings()
    rs = requests.sessions.Session()
    # éœ€è·³è½‰ 18 ç¦ç™»å…¥é é¢
    payload = {'from': href,'yes': 'yes'}
    res = rs.post('https://www.ptt.cc/ask/over18', verify=False, data=payload)
    soup = BeautifulSoup(res.text, 'html.parser')

    pre_href = soup.select('div.btn-group a')[3]['href']
    board = pre_href.split('/')[2]
    pre_index = re.search('\d+', pre_href).group()
    index = int(pre_index)
    up_href = "/bbs/{}/index".format(board)

    for page in range(pages - 1):
        whole_href = up_href + str(index) + ".html"
        index -= 1
        href_list.append(whole_href)

    return href_list

# ptt articles
def ptt_article(ptt_board_url, over_rate):
    """
    ptt_board_url:str :please input ptt board url
    over_rate:int :please input a number which is rate threshold

    return ptt articles which > rate
    """
    articles = []
    url_list = ptt_upper_url(ptt_board_url, 5)
    for url in url_list:
        rs = requests.sessions.Session()
        res = rs.get(url,headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')

        for r_ent in soup.select('div.r-ent'):
            try:
                href_ = r_ent.select_one('a')
                if href_ != None:
                    link = 'https://www.ptt.cc' + href_['href']  # æ¯ç¯‡æ–‡ç« çš„é€£çµ
                    title = href_.text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ¨™é¡Œ
                    title = del_re(title)
                    if len(title)>20:
                        title = title[:20]+"..."
                    else:
                        title=title
                    rate = r_ent.select_one('div.nrec').text  # æ¯ç¯‡æ–‡ç« çš„ç•™è¨€æ•¸
                    date = r_ent.select_one('.date').text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ—¥æœŸ
                    if rate != None:
                        if rate.isnumeric() and int(rate) >= over_rate:
                            rate = 'æ¨{}'.format(rate)
                            articles.append({'date': date, 'rate': rate, 'title': title, 'link': link})
                        else:
                            if rate.startswith('X'):
                                rate = 'å™“ğŸ–•'
                                articles.append({'date': date, 'rate': rate, 'title': title, 'link': link})
                            if rate == 'çˆ†':
                                rate = 'çˆ†ğŸ”¥'
                                articles.append({'date': date, 'rate': rate, 'title': title, 'link': link})
            except Exception as e:
                print('æ–‡ç« å·²åˆªé™¤', e)

    return articles

# ptt over18 articles
def ptt_over18_article(href, over_rate):
    """
    href:str :please input href, Ex:"/bbs/sex/index.html", "/bbs/Gossiping/index.html"
    over_rate:int :please input a number which is rate threshold

    return ptt articles which > rate
    """
    articles = []
    href_list = ptt_over18_href(href, 10)
    for _href in href_list:
        urllib3.disable_warnings()
        rs = requests.sessions.Session()
        # éœ€è·³è½‰ 18 ç¦ç™»å…¥é é¢
        payload = {'from': _href, 'yes': 'yes'}
        res = rs.post('https://www.ptt.cc/ask/over18', verify=False, data=payload)
        soup = BeautifulSoup(res.text, 'html.parser')

        for r_ent in soup.select('div.r-ent'):
            try:
                href_ = r_ent.select_one('a')
                if href_ != None:
                    link = 'https://www.ptt.cc' + href_['href']  # æ¯ç¯‡æ–‡ç« çš„é€£çµ
                    title = href_.text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ¨™é¡Œ
                    title = del_re(title)
                    if len(title)>20:
                        title = title[:20]+"..."
                    else:
                        title=title
                    rate = r_ent.select_one('div.nrec').text  # æ¯ç¯‡æ–‡ç« çš„ç•™è¨€æ•¸
                    date = r_ent.select_one('.date').text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ—¥æœŸ
                    if rate != None:
                        if rate.isnumeric() and int(rate) >= over_rate:
                            rate = 'æ¨{}'.format(rate)
                            articles.append({'date': date, 'rate': rate, 'title': title, 'link': link})
                        else:
                            if rate.startswith('X'):
                                rate = 'å™“ğŸ–•'
                                articles.append({'date': date, 'rate': rate, 'title': title, 'link': link})
                            if rate == 'çˆ†':
                                rate = 'çˆ†ğŸ”¥'
                                articles.append({'date': date, 'rate': rate, 'title': title, 'link': link})
            except Exception as e:
                print('æ–‡ç« å·²åˆªé™¤', e)

    return articles



# ptt_nbaç‰ˆ æ–‡ç« 
def ptt_nba():
    articles = ptt_article('https://www.ptt.cc/bbs/NBA/index.html',50)
    random.shuffle(articles)

    content = '<ç±ƒçƒç‰ˆ 0{}>\n{}\n\n'.format(today_date(),'='*13)
    for index ,article in enumerate(articles,1):
        if index == 5 :
            return content
        data = '<{}> {}\n{}\n\n'.format(article.get('rate'),article.get('title'), article.get('link'))
        content += data

    return content

# C_Chat è¨è«–ç‰ˆ æ–‡ç« 
def ptt_C_Chat():
    articles = ptt_article('https://www.ptt.cc/bbs/C_Chat/index.html', 40)
    random.shuffle(articles)

    content = 'é–’è«‡ç‰ˆ <0{}>\n{}\n\n'.format(today_date(),'='*13)
    for index ,article in enumerate(articles,1):
        if article.get('date') == today_date():
            if index == 5:
                return content
            data = '<{}> {}\n{}\n\n'.format(article.get('rate'),article.get('title'), article.get('link'))
            content += data

    return content

# Sex è¥¿æ–¯ç‰ˆ æ–‡ç« 
def ptt_sex():
    articles = ptt_over18_article('/bbs/sex/index.html', 50)
    random.shuffle(articles)

    content = 'è¥¿æ–¯ç‰ˆ <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, article in enumerate(articles, 1):
        if index == 5:
            return content
        data = '<{}> {}\n{}\n\n'.format(article.get('rate'), article.get('title'), article.get('link'))
        content += data

    return content

# HatePolitics é»‘ç‰¹æ”¿æ²»ç‰ˆ æ–‡ç« 
def ptt_HatePolitics():
    articles = ptt_over18_article('/bbs/HatePolitics/index.html',30)
    random.shuffle(articles)

    content = 'é»‘æ”¿ç‰ˆ <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, article in enumerate(articles, 1):
        if article.get('date') == today_date():
            if index == 5:
                return content
            data = '<{}> {}\n{}\n\n'.format(article.get('rate'), article.get('title'), article.get('link'))
            content += data

    return content

# Stock è‚¡ç¥¨ç‰ˆ æ–‡ç« 
def ptt_stock():
    articles = ptt_article('https://www.ptt.cc/bbs/Stock/index.html',40)
    random.shuffle(articles)

    content = 'è‚¡ç¥¨ç‰ˆ <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, article in enumerate(articles, 1):
        if article.get('date') == today_date():
            if index == 5:
                return content
            data = '<{}> {}\n{}\n\n'.format(article.get('rate'), article.get('title'), article.get('link'))
            content += data

    return content

# Beauty è¡¨ç‰¹ç‰ˆ æ–‡ç« 
def ptt_beauty_crawl(href):
    urllib3.disable_warnings()
    pay_load = {'from': href, 'yes': 'yes'}

    rs = requests.sessions.Session()
    res = rs.post('https://www.ptt.cc/ask/over18', verify=False, data=pay_load)
    soup = BeautifulSoup(res.text, 'html.parser')

    return soup

def ptt_beauty():
    rate_filter = []

    while len(rate_filter) <= 0:
        index = str(random.randint(2000, 3050))

        hot_soup = ptt_beauty_crawl('/bbs/Beauty/index{}.html'.format(index))
        hot = hot_soup.select('div.r-ent')

        for i in hot:
            if i.select_one('span'):
                if i.select_one('span').text.isnumeric():
                    if int(i.select_one('span').text) > 50:
                        rate_filter.append(i.select_one('a').get('href'))

    article = random.choice(rate_filter)
    soup_imgur = ptt_beauty_crawl(article)
    imgur_link = [href['href'] for href in soup_imgur.select('div a') if ".jpg" in href['href']]

    return imgur_link[0]


### æ–°èNews
# ç‹‚æ–°è
def news_crazy_new():
    urllib3.disable_warnings()
    target_url = 'https://ck101.com/'
    rs = requests.session()
    res = rs.get(target_url, headers=headers, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')
    articles = []
    upper = soup.select('div.newPosts__upper h4 a')
    for unews in upper:
        title = unews.text.strip()
        link = unews.get('href')
        articles.append({'title': title, 'link': link})
    time.sleep(1)
    bottom = soup.select('div.newPosts__bottom h4 a')
    for bnews in bottom:
        title = bnews.text.strip()
        link = bnews.get('href')
        articles.append({'title': title, 'link': link})

    random.shuffle(articles)
    content = '<å¡æè«¾ç‹‚æ–°è>\n{}\n'.format('========')
    for index, article in enumerate(articles, 1):
        if index == 6:
            return content
        content += '[ç‹‚] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# æœ€æ–°ç‹‚å½±ç‰‡
def news_crazy_video():
    urllib3.disable_warnings()
    target_url = "https://ck101.com/forum.php?mod=forumdisplay&fid=3731"
    rs = requests.session()
    res = rs.get(target_url ,headers=headers ,verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for video in soup.select('h3 a'):
        string = video.get('onclick')
        if string != None:
            title = video.get('title').strip()
            link = re.findall(r'http://ck101.com/.*.html',string).pop()
            articles.append({'title':title,'link':link})

    content = '<å¡æè«¾ç‹‚å½±é›†>\n{}\n'.format('========')
    for index ,article in enumerate(articles,1):
        if index == 5:
            return content
        content += '[ç‹‚] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# ç‹‚æƒ¡æ kuso
def news_crazy_kuso():
    urllib3.disable_warnings()
    target_url = 'https://ck101.com/forum.php?mod=forumdisplay&fid=3607&page=1'
    rs = requests.session()
    res = rs.get(target_url, headers=headers, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for kuso in soup.select('div.blockTitle a'):
        string = kuso.get('onclick')
        if string != None:
            title = kuso.get('title').strip()
            link = re.findall(r'http://ck101.com/.*.html', string).pop()
            articles.append({'title': title, 'link': link})

    # ç¬¬ä¸€å‰‡ç‚ºç‰ˆè¦
    articles = articles[1:]
    random.shuffle(articles)
    content = '<å¡æè«¾ç‹‚Kuso>\n{}\n'.format('========')
    for index, article in enumerate(articles, 1):
        if index == 8:
            return content
        content += '[ç‹‚] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# ETtodayæ–°è ç†±é–€
def news_ETtoday():
    target_url = 'https://www.ettoday.net/news/hot-news.htm'
    rs = requests.session()
    res = rs.get(target_url ,headers=headers ,verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for news in soup.select('div.part_pictxt_3 h3'):
        title = news.text.strip()
        link = 'https://www.ettoday.net/' + news.select_one('a')['href']
        articles.append({'title':title,'link':link})

    random.shuffle(articles)
    content = 'ETtoday <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index ,article in enumerate(articles,1):
        if index == 6:
            return content
        content += '[ET] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# è˜‹æœå³æ™‚æ–°è
def news_Apple():
    target_url = 'https://tw.appledaily.com/new/realtime'
    rs = requests.session()
    res = rs.get(target_url, headers=headers, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for news in soup.select('li a')[3:-6]:
        title = news.select_one('h1').text.strip()
        link = news.get('href')
        articles.append({'title': title, 'link': link})

    random.shuffle(articles)
    content = 'AppleNews <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, article in enumerate(articles, 1):
        if index == 6:
            return content
        content += '[Apple] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# ç§‘æŠ€æ–°è tech
def technews():
    target_url = 'https://technews.tw/'
    print('Start parsing movie ...')
    rs = requests.session()
    res = rs.get(target_url, verify=False)
    res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')

    content = 'Technews <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, data in enumerate(soup.select('article div h1.entry-title a')):
        if index == 6:
            return content
        title = data.text
        link = data['href']
        content += '[Tech] {}\n{}\n\n'.format(title, link)

    return content

def panx():
    target_url = "https://panx.asia/"
    print('Start parsing ptt hot....')
    rs = requests.session()
    res = rs.get(target_url, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    content = 'PanXæ³›ç§‘æŠ€ <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for data in soup.select('div.container div.row div.desc_wrap h2 a'):
        title = data.text
        link = data['href']
        content += '[æ³›] {}\n{}\n\n'.format(title, link)

    return content



# å¦‚æœ user å‚³ä»€éº¼{ï¼¿ï¼¿}ï¼Œå›å‚³åˆ° MessageEvent
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    print("event.reply_token:", event.reply_token)
    print("event.message.text:", event.message.text)

    # NBAæ–‡ç« 
    # ============================================
    if event.message.text in ['Nba','nba','NBA','ç±ƒçƒ']:
        content = ptt_nba()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Chat æ–‡ç« 
    # ============================================
    if event.message.text in ['chat','Chat','CHAT','C_Chat']:
        content = ptt_C_Chat()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Stock æ–‡ç« 
    # ============================================
    if event.message.text in ['stock', 'è‚¡ç¥¨', 'Stock', 'STOCK']:
        content = ptt_stock()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Haters æ–‡ç« 
    # ============================================
    if event.message.text in ['hater','haters','Hater','Haters']:
        content = ptt_HatePolitics()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Sex æ–‡ç« 
    # ============================================
    if event.message.text in ['sex','Sex','SEX','è¥¿æ–¯']:
        content = ptt_sex()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Beauty æ–‡ç« 
    # ============================================
    if event.message.text in ["è¡¨ç‰¹æ­£å¦¹","è¡¨ç‰¹","Beauty","beauty"]:
        imgur_url = ptt_beauty()
        image_message = ImageSendMessage(
            original_content_url=imgur_url,
            preview_image_url=imgur_url
        )
        line_bot_api.reply_message(
            event.reply_token, image_message)
        return 0

    # æ–°èNews
    # ============================================
    if event.message.text == "ç‹‚æ–°è":
        content = news_crazy_new()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ç‹‚å½±ç‰‡":
        content = news_crazy_video()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ç‹‚kuso":
        content = news_crazy_kuso()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ETtoday":
        content = news_ETtoday()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "è˜‹æœæ–°è":
        content = news_Apple()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "PanXæ³›ç§‘æŠ€":
        content = panx()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ç§‘æŠ€æ–°å ±":
        content = technews()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # åœ–ç‰‡è¨Šæ¯
    if event.message.text in ["æ­£å¦¹","æ­£å¦¹åœ–"]:
        client = ImgurClient(client_id, client_secret, access_token, refresh_token)
        images = client.get_album_images(album_id)
        index = random.randint(0, len(images) - 1)
        url = images[index].link
        image_message = ImageSendMessage(
            original_content_url=url,
            preview_image_url=url
        )
        line_bot_api.reply_message(
            event.reply_token, image_message)
        time.sleep(1)
        return 0


    # åœ–æ–‡è¨Šæ¯
    # ============================================
    if event.message.text == 'é–‹å§‹':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://i.imgur.com/1imVDpJ.png',
                title='æˆ‘æ˜¯é„‰æ°‘30CM',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='ä¾†ç•¶å€‹é„‰æ°‘',
                        text='ptt'
                    ),
                    MessageTemplateAction(
                        label='ä¾†çœ‹å€‹æ–°è',
                        text='æ–°è'
                    ),
                    MessageTemplateAction(
                        label='è¡¨ç‰¹æ­£å¦¹åœ–',
                        text='Beauty'
                    ),
                    MessageTemplateAction(
                        label='ä¾†é»æ­£å¦¹åœ–',
                        text='æ­£å¦¹'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'æ–°è':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://365psd.com/images/previews/1d0/psd-news-icon-53281.jpg',
                title='æ–°èé€²è¡Œå¼',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='å¡æè«¾ç‹‚æ–°è',
                        text='å¡æè«¾'
                    ),
                    MessageTemplateAction(
                        label='ETtodayæ–°è',
                        text='ETtoday'
                    ),
                    MessageTemplateAction(
                        label='è˜‹æœå‹•æ–°è',
                        text='è˜‹æœæ–°è'
                    ),
                    MessageTemplateAction(
                        'ç§‘æŠ€æ–°è',
                        text='ç§‘æŠ€æ–°è'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'å¡æè«¾':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://img.ltn.com.tw/Upload/liveNews/BigPic/600_phpg6IvSl.jpg',
                title='å¡æè«¾ç‹‚æ–°è',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='ç†±é–€ç‹‚æ–°è',
                        text='ç‹‚æ–°è'
                    ),
                    MessageTemplateAction(
                        label='å¡æè«¾ç‹‚å½±é›†',
                        text='ç‹‚å½±ç‰‡'
                    ),
                    MessageTemplateAction(
                        label='å¡æè«¾KUSO',
                        text='ç‹‚kuso'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'ç§‘æŠ€æ–°è':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2019/02/Techcircle.jpg',
                title='Technology News',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='PanX æ³›ç§‘æŠ€',
                        text='PanXæ³›ç§‘æŠ€'
                    ),
                    MessageTemplateAction(
                        label='TechNews',
                        text='ç§‘æŠ€æ–°å ±'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'ptt':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://photo.sofun.tw/2015/06/Aotter-PTT-Logo.png',
                title='Menu',
                text='è«‹é¸æ“‡ä»»ä¸€ç‰ˆ',
                actions=[
                    MessageTemplateAction(
                        label='NBA(ç±ƒçƒç‰ˆ)',
                        text='nba'
                    ),
                    MessageTemplateAction(
                        label='Sex(è¥¿æ–¯ç‰ˆ)',
                        text='sex'
                    ),
                    MessageTemplateAction(
                        label='C_Chat(é–’è«‡ç‰ˆ)',
                        text='chat'
                    ),
                    MessageTemplateAction(
                        label='HatePoli(æ”¿é»‘ç‰ˆ)',
                        text='hater'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

# æœ€å¾Œä¸Šå‚³ Heroku
if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
