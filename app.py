# import need packages
import os
import requests
from bs4 import BeautifulSoup
import urllib3

import re
import time
import random
import datetime
from imgurpython import ImgurClient

# linebot-sdk packages
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *


app = Flask(__name__)

# Line Messenger API for your channels
Channel_Access_Token = "Line developers çš„ Channel_Access_Token"
line_bot_api = LineBotApi(Channel_Access_Token)

# Channel Secret
Channel_Secret = "Line developers çš„ Channel_Secret"
handler = WebhookHandler(Channel_Secret)

# Imgur åœ–ç‰‡ç¶²ç«™ api
client_id = 'imgur å¸³è™Ÿ client_id'
client_secret = 'imgur å¸³è™Ÿ client_secret'
access_token = 'postman get access_token'
refresh_token = 'postman get refresh_token'
album_id = 'albumç¶²å€/a/å¾Œæ–¹è‹±æ–‡'

# requests.get å½è£å™¨
headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.63 Safari/537.36"}

@app.route("/callback", methods=['POST'])
def callback():
    # get X-Line-Signature header value
    signature = request.headers['X-Line-Signature']

    # get request body as text
    body = request.get_data(as_text=True)
    # print("body:",body)
    app.logger.info("Request body: " + body)

    # handle webhook body
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'ok'

# è™•ç† title æ–‡å­—
def del_re(string):
    import re
    if re.search(r'^Re.\s*',string) != None:
        count = re.search(r'^Re.\s*',string).span()[1]
        return string[count:]
    else:
        return string

# ä»Šæ—¥æ™‚é–“
def today_date():
    today = datetime.date.today()
    today_format = today.strftime(("%m/%d"))[1:]
    return today_format

# æ˜¨æ—¥æ™‚é–“
def yesterday_date():
    yesterday = datetime.date.today() + datetime.timedelta(-1)
    yesterday_format = yesterday.strftime("%m/%d")[1:]
    return yesterday_format

# æŠ“å–ä¸Šä¸€é çš„ url
def upper_url(url,times=3):
    url_list = [url]
    for i in range(times):
        res = requests.get(url)
        soup = BeautifulSoup(res.text,"html.parser")
        up_page_href = soup.select('div.btn-group a')[3]['href']
        up_page_url = 'https://www.ptt.cc' + up_page_href
        url_list.append(up_page_url)
        url = up_page_url
    return url_list


# ptt_nbaç‰ˆ æ–‡ç« 
# ================================================
def ptt_nba():
    articles = []
    curr_url = 'https://www.ptt.cc/bbs/NBA/index.html'
    url_list = upper_url(curr_url)
    for url in url_list:
        rs = requests.sessions.Session()
        res = rs.get(url,headers=headers)
        soup = BeautifulSoup(res.text,'html.parser')
        for r_ent in soup.select('div.r-ent'):
            try:
                href_ = r_ent.select_one('a')
                if href_ != None:
                    link = 'https://www.ptt.cc' + href_['href']    # æ¯ç¯‡æ–‡ç« çš„é€£çµ
                    title = href_.text.strip()                     # æ¯ç¯‡æ–‡ç« çš„æ¨™é¡Œ
                    rate = r_ent.select_one('div.nrec').text       # æ¯ç¯‡æ–‡ç« çš„ç•™è¨€æ•¸
                    date = r_ent.select_one('.date').text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ—¥æœŸ
                    if rate != None:
                        if rate.isnumeric() and int(rate) >= 50:
                            rate = 'æ¨{}'.format(rate)
                            articles.append({'date':date ,'rate':rate,'title':del_re(title) ,'link':link})
                        else:
                            if rate.startswith('X'):
                                rate = 'å™“ğŸ¤«'
                                articles.append({'date':date ,'rate':rate ,'title':del_re(title) ,'link':link})
                            if rate == 'çˆ†':
                                rate = 'çˆ†ğŸ”¥'
                                articles.append({'date':date ,'rate':rate ,'title':del_re(title) ,'link':link})
            except Exception as e:
                print('æ–‡ç« å·²è¢«åˆªé™¤', e)

    random.shuffle(articles)
    content = '<ç±ƒçƒç‰ˆ 0{}>\n{}\n\n'.format(today_date(),'='*13)
    for index ,article in enumerate(articles,1):
        if index == 6 :
            return content
        data = '<{}>{}\n{}\n\n'.format(article.get('rate'),article.get('title'), article.get('link'))
        content += data

    return content


# C_Chat è¨è«–ç‰ˆ æ–‡ç« 
# ================================================
def ptt_C_Chat():
    articles = []
    curr_url = 'https://www.ptt.cc/bbs/C_Chat/index.html'
    url_list = upper_url(curr_url,5)
    for url in url_list:
        rs = requests.sessions.Session()
        res = rs.get(url,headers=headers)
        soup = BeautifulSoup(res.text,'html.parser')
        for r_ent in soup.select('div.r-ent'):
            try:
                href_ = r_ent.select_one('a')
                if href_ != None:
                    link = 'https://www.ptt.cc' + href_['href']    # æ¯ç¯‡æ–‡ç« çš„é€£çµ
                    title = href_.text.strip()                     # æ¯ç¯‡æ–‡ç« çš„æ¨™é¡Œ
                    rate = r_ent.select_one('div.nrec').text       # æ¯ç¯‡æ–‡ç« çš„ç•™è¨€æ•¸
                    date = r_ent.select_one('.date').text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ—¥æœŸ
                    if rate != None:
                        if rate.isnumeric() and int(rate) >= 15:
                            rate = 'æ¨{}'.format(rate)
                            articles.append({'date':date ,'rate':rate,'title':del_re(title) ,'link':link})
                        else:
                            if rate.startswith('X'):
                                rate = 'å™“ğŸ¤«'
                                articles.append({'date':date ,'rate':rate ,'title':del_re(title) ,'link':link})
                            if rate == 'çˆ†':
                                rate = 'çˆ†ğŸ”¥'
                                articles.append({'date':date ,'rate':rate ,'title':del_re(title) ,'link':link})
            except Exception as e:
                print('æ–‡ç« å·²è¢«åˆªé™¤', e)

    random.shuffle(articles)
    content = 'é–’è«‡ç‰ˆ <0{}>\n{}\n\n'.format(today_date(),'='*13)
    for index ,article in enumerate(articles,1):
        if article.get('date') == today_date():
            if index == 6:
                return content
            data = '<{}>{}\n{}\n\n'.format(article.get('rate'),article.get('title'), article.get('link'))
            content += data

    return content

# HatePolitics é»‘ç‰¹æ”¿æ²»ç‰ˆ æ–‡ç« 
# ================================================
def ptt_HatePolitics():
    articles = []
    curr_url = 'https://www.ptt.cc/bbs/HatePolitics/index.html'
    url_list = upper_url(curr_url,5)
    for url in url_list:
        rs = requests.sessions.Session()
        res = rs.get(url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')
        for r_ent in soup.select('div.r-ent'):
            try:
                href_ = r_ent.select_one('a')
                if href_ != None:
                    link = 'https://www.ptt.cc' + href_['href']  # æ¯ç¯‡æ–‡ç« çš„é€£çµ
                    title = href_.text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ¨™é¡Œ
                    rate = r_ent.select_one('div.nrec').text  # æ¯ç¯‡æ–‡ç« çš„ç•™è¨€æ•¸
                    date = r_ent.select_one('.date').text.strip()  # æ¯ç¯‡æ–‡ç« çš„æ—¥æœŸ
                    if rate != None:
                        if rate.isnumeric() and int(rate) >= 15:
                            rate = 'æ¨{}'.format(rate)
                            articles.append({'date': date, 'rate': rate, 'title': del_re(title), 'link': link})
                        else:
                            if rate.startswith('X'):
                                rate = 'å™“ğŸ¤«'
                                articles.append({'date': date, 'rate': rate, 'title': del_re(title), 'link': link})
                            if rate == 'çˆ†':
                                rate = 'çˆ†ğŸ”¥'
                                articles.append({'date': date, 'rate': rate, 'title': del_re(title), 'link': link})
            except Exception as e:
                print('æ–‡ç« å·²è¢«åˆªé™¤', e)

    content = 'é»‘æ”¿ç‰ˆ <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, article in enumerate(articles, 1):
        if article.get('date') == today_date():
            if index == 10:
                return content
            data = '<{}>{}\n{}\n\n'.format(article.get('rate'), article.get('title'), article.get('link'))
            content += data

    return content


# Sex è¥¿æ–¯ç‰ˆ æ–‡ç« 
# ================================================
def ptt_sex():
    urllib3.disable_warnings()
    rs = requests.sessions.Session()
    # éœ€è·³è½‰ 18 ç¦ç™»å…¥é é¢
    load = {
        'from': '/bbs/sex/index.html',
        'yes': 'yes'
    }
    res = rs.post('https://www.ptt.cc/ask/over18', verify=False, data=load)
    soup = BeautifulSoup(res.text,'html.parser')
    article_dict = []
    for r_ent in soup.select('div.r-ent'):
        try:
            href_ = r_ent.select_one('a')
            if href_ != None:
                title = href_.text.strip()
                rate = r_ent.select_one('div.nrec').text
                url = 'https://www.ptt.cc' + href_['href']
                if rate != None:
                    if rate.isnumeric():
                        rate = 'æ¨{}'.format(rate)
                    elif rate.startswith('X'):
                        rate = 'å™“ğŸ¤«'
                    else:
                        rate = 'ğŸˆ²'+rate
                    article_dict.append({'title':title,'url':url,'rate':rate})
        except Exception as e:
            print('æœ¬æ–‡å·²è¢«åˆªé™¤', e)

    random.shuffle(article_dict)
    content = 'è¥¿æ–¯ç‰ˆ <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, article in enumerate(article_dict, 0):
        if index == 10:
            return content
        data = '<{}>{}\n{}\n\n'.format(article.get('rate'),article.get('title'), article.get('url'))
        content += data

    return content


##*æ–°èNews
# ç‹‚æ–°è
# ================================================
def news_crazy_new():
    urllib3.disable_warnings()
    target_url = 'https://ck101.com/'
    rs = requests.session()
    res = rs.get(target_url, headers=headers, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')
    articles = []
    upper = soup.select('div.newPosts__upper h4 a')
    for unews in upper:
        title = unews.text.strip()
        link = unews.get('href')
        articles.append({'title': title, 'link': link})
    time.sleep(1)
    bottom = soup.select('div.newPosts__bottom h4 a')
    for bnews in bottom:
        title = bnews.text.strip()
        link = bnews.get('href')
        articles.append({'title': title, 'link': link})

    random.shuffle(articles)
    content = '<å¡æè«¾ç‹‚æ–°è>\n{}\n'.format('========')
    for index, article in enumerate(articles, 1):
        if index == 6:
            return content
        content += '[ç‹‚] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# æœ€æ–°ç‹‚å½±ç‰‡
def news_crazy_video():
    urllib3.disable_warnings()
    target_url = "https://ck101.com/forum.php?mod=forumdisplay&fid=3731"
    rs = requests.session()
    res = rs.get(target_url ,headers=headers ,verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for video in soup.select('h3 a'):
        string = video.get('onclick')
        if string != None:
            title = video.get('title').strip()
            link = re.findall(r'http://ck101.com/.*.html',string).pop()
            articles.append({'title':title,'link':link})

    content = '<å¡æè«¾ç‹‚å½±é›†>\n{}\n'.format('========')
    for index ,article in enumerate(articles,1):
        if index == 5:
            return content
        content += '[ç‹‚] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# ç‹‚æƒ¡æ kuso
def news_crazy_kuso():
    urllib3.disable_warnings()
    target_url = 'https://ck101.com/forum.php?mod=forumdisplay&fid=3607&page=1'
    rs = requests.session()
    res = rs.get(target_url, headers=headers, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for kuso in soup.select('div.blockTitle a'):
        string = kuso.get('onclick')
        if string != None:
            title = kuso.get('title').strip()
            link = re.findall(r'http://ck101.com/.*.html', string).pop()
            articles.append({'title': title, 'link': link})

    # ç¬¬ä¸€å‰‡ç‚ºç‰ˆè¦
    articles = articles[1:]
    random.shuffle(articles)
    content = '<å¡æè«¾ç‹‚Kuso>\n{}\n'.format('========')
    for index, article in enumerate(articles, 1):
        if index == 8:
            return content
        content += '[ç‹‚] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# ETtodayæ–°è ç†±é–€
# ================================================
def news_ETtoday():
    target_url = 'https://www.ettoday.net/news/hot-news.htm'
    rs = requests.session()
    res = rs.get(target_url ,headers=headers ,verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for news in soup.select('div.part_pictxt_3 h3'):
        title = news.text.strip()
        link = 'https://www.ettoday.net/' + news.select_one('a')['href']
        articles.append({'title':title,'link':link})

    random.shuffle(articles)
    content = 'ETtoday <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index ,article in enumerate(articles,1):
        if index == 6:
            return content
        content += '[ET] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# è˜‹æœå³æ™‚æ–°è
# ================================================
def news_Apple():
    target_url = 'https://tw.appledaily.com/new/realtime'
    rs = requests.session()
    res = rs.get(target_url, headers=headers, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    time.sleep(1)
    articles = []
    for news in soup.select('li a')[3:-6]:
        title = news.select_one('h1').text.strip()
        link = news.get('href')
        articles.append({'title': title, 'link': link})

    random.shuffle(articles)
    content = 'AppleNews <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, article in enumerate(articles, 1):
        if index == 6:
            return content
        content += '[Apple] {}\n{}\n\n'.format(article.get('title'), article.get('link'))

    return content

# ç§‘æŠ€æ–°è tech
# ================================================
def technews():
    target_url = 'https://technews.tw/'
    print('Start parsing movie ...')
    rs = requests.session()
    res = rs.get(target_url, verify=False)
    res.encoding = 'utf-8'
    soup = BeautifulSoup(res.text, 'html.parser')

    content = 'technews <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for index, data in enumerate(soup.select('article div h1.entry-title a')):
        if index == 6:
            return content
        title = data.text
        link = data['href']
        content += '[tech]{}\n{}\n\n'.format(title, link)

    return content

def panx():
    target_url = "https://panx.asia/"
    print('Start parsing ptt hot....')
    rs = requests.session()
    res = rs.get(target_url, verify=False)
    soup = BeautifulSoup(res.text, 'html.parser')

    content = 'PanXæ³›ç§‘æŠ€ <0{}>\n{}\n\n'.format(today_date(), '=' * 13)
    for data in soup.select('div.container div.row div.desc_wrap h2 a'):
        title = data.text
        link = data['href']
        content += '[æ³›]{}\n{}\n\n'.format(title, link)

    return content




# å¦‚æœ user å‚³ä»€éº¼{ï¼¿ï¼¿}ï¼Œå›å‚³åˆ° MessageEvent
# ================================================
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    print("event.reply_token:", event.reply_token)
    print("event.message.text:", event.message.text)

    # NBAæ–‡ç« 
    # ============================================
    if event.message.text in ['Nba','nba','NBA','ç±ƒçƒ']:
        content = ptt_nba()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Chat æ–‡ç« 
    # ============================================
    if event.message.text in ['chat','Chat','C_Chat']:
        content = ptt_C_Chat()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Haters æ–‡ç« 
    # ============================================
    if event.message.text in ['hater', 'haters', 'Haters', 'é»‘ç‰¹æ”¿å®¢']:
        content = ptt_HatePolitics()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # Sex æ–‡ç« 
    # ============================================
    if event.message.text in ['sex','Sex','SEX','è¥¿æ–¯']:
        content = ptt_sex()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0


    # æ–°èNews
    # ============================================
    if event.message.text == "ç‹‚æ–°è":
        content = news_crazy_new()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ç‹‚å½±ç‰‡":
        content = news_crazy_video()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ç‹‚kuso":
        content = news_crazy_kuso()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ETtoday":
        content = news_ETtoday()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "è˜‹æœæ–°è":
        content = news_Apple()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "PanXæ³›ç§‘æŠ€":
        content = panx()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    if event.message.text == "ç§‘æŠ€æ–°å ±":
        content = technews()
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=content))
        return 0

    # åœ–ç‰‡è¨Šæ¯è™•ç†
    # ============================================
    if event.message.text == "æ­£å¦¹åœ–":
        client = ImgurClient(client_id, client_secret, access_token, refresh_token)
        images = client.get_album_images(album_id)
        index = random.randint(0, len(images) - 1)
        url = images[index].link
        image_message = ImageSendMessage(
            original_content_url=url,
            preview_image_url=url
        )
        line_bot_api.reply_message(
            event.reply_token, image_message)
        return 0


    # åœ–æ–‡è¨Šæ¯
    # ============================================
    if event.message.text == 'é–‹å§‹':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://i.imgur.com/1imVDpJ.png',
                title='æˆ‘æ˜¯é„‰æ°‘30CM',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='ä¾†ç•¶å€‹é„‰æ°‘',
                        text='ptt'
                    ),
                    MessageTemplateAction(
                        label='ä¾†çœ‹å€‹æ–°è',
                        text='æ–°è'
                    ),
                    MessageTemplateAction(
                        label='ä¾†é»æ­£å¦¹åœ–',
                        text='æ­£å¦¹åœ–'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'æ–°è':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://365psd.com/images/previews/1d0/psd-news-icon-53281.jpg',
                title='æ–°èé€²è¡Œå¼',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='å¡æè«¾ç‹‚æ–°è',
                        text='å¡æè«¾'
                    ),
                    MessageTemplateAction(
                        label='ETtodayæ–°è',
                        text='ETtoday'
                    ),
                    MessageTemplateAction(
                        label='è˜‹æœå‹•æ–°è',
                        text='è˜‹æœæ–°è'
                    ),
                    MessageTemplateAction(
                        'ç§‘æŠ€æ–°è',
                        text='ç§‘æŠ€æ–°è'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'å¡æè«¾':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://img.ltn.com.tw/Upload/liveNews/BigPic/600_phpg6IvSl.jpg',
                title='å¡æè«¾ç‹‚æ–°è',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='ç†±é–€ç‹‚æ–°è',
                        text='ç‹‚æ–°è'
                    ),
                    MessageTemplateAction(
                        label='å¡æè«¾ç‹‚å½±é›†',
                        text='ç‹‚å½±ç‰‡'
                    ),
                    MessageTemplateAction(
                        label='å¡æè«¾KUSO',
                        text='ç‹‚kuso'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'ç§‘æŠ€æ–°è':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2019/02/Techcircle.jpg',
                title='Technology News',
                text='è«‹é¸æ“‡å…§å®¹',
                actions=[
                    MessageTemplateAction(
                        label='PanX æ³›ç§‘æŠ€',
                        text='PanXæ³›ç§‘æŠ€'
                    ),
                    MessageTemplateAction(
                        label='TechNews',
                        text='ç§‘æŠ€æ–°å ±'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

    if event.message.text == 'ptt':
        buttons_template = TemplateSendMessage(
            alt_text='Buttons template',
            template=ButtonsTemplate(
                thumbnail_image_url='https://photo.sofun.tw/2015/06/Aotter-PTT-Logo.png',
                title='Menu',
                text='è«‹é¸æ“‡ä»»ä¸€ç‰ˆ',
                actions=[
                    MessageTemplateAction(
                        label='NBA(ç±ƒçƒç‰ˆ)',
                        text='nba'
                    ),
                    MessageTemplateAction(
                        label='Sex(è¥¿æ–¯ç‰ˆ)',
                        text='sex'
                    ),
                    MessageTemplateAction(
                        label='C_Chat(é–’è«‡ç‰ˆ)',
                        text='chat'
                    ),
                    MessageTemplateAction(
                        label='HatesPoli(æ”¿é»‘ç‰ˆ)',
                        text='hater'
                    )
                ]
            )
        )
        line_bot_api.reply_message(event.reply_token, buttons_template)
        return 0

# æœ€å¾Œä¸Šå‚³ Heroku
if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
